## ğŸ§® **NovaX** â€” GPU-Accelerated Math for Python

> ğŸš€ *Explosive performance. Minimal code. One unified tensor library.*

NovaX is a lightweight, modular math library that brings GPU acceleration to standard Python numeric workflows.
Itâ€™s designed for speed, simplicity, and extensibility â€” combining familiar NumPy-style operations with CUDA-backed computation.

---

### âš¡ï¸ **Features**

* ğŸ”¹ **GPU acceleration** via **PyCUDA** and **CUDA-Python**
* ğŸ”¹ Clean **NumPy-like API** (`import novax as nx`)
* ğŸ”¹ Seamless **CPU â†” GPU transfer** (`.to_gpu()` / `.to_host()`)
* ğŸ”¹ Built-in **elementwise ops**: `add`, `sub`, `mul`, `div`
* ğŸ”¹ Lazy evaluation and **expression graph support**
* ğŸ”¹ **Extensible kernel system** (add your own CUDA ops)
* ğŸ”¹ Optional dependency system: install lightweight or GPU-enabled

---

### ğŸ§© **Installation**

#### CPU-only:

```bash
pip install novax
```

#### GPU-enabled (PyCUDA + CUDA):

```bash
pip install "novax[gpu]"
```

Or install directly from GitHub:

```bash
pip install git+https://github.com/SS-012/novax.git
```

---

### ğŸ’» **Quick Start**

```python
import novax as nx
import numpy as np

# Create tensors
a = nx.Tensor(np.arange(5))
b = nx.Tensor(np.ones(5))

# Upload to GPU
a.to_gpu()
b.to_gpu()

# Perform GPU addition
res = nx.add(a, b)

# Bring results back to host
print(res.to_host())
```

**Output:**

```
[1. 2. 3. 4. 5.]
```

---

### âš™ï¸ **Architecture Overview**

```
novax/
â”œâ”€â”€ core.py          # Tensor class & computation graph
â”œâ”€â”€ ops/             # CPU and GPU operation modules
â”‚   â”œâ”€â”€ cpu/         # NumPy fallbacks
â”‚   â””â”€â”€ gpu/         # PyCUDA kernels
â”œâ”€â”€ utils/           # Memory management (GPU pool)
â”œâ”€â”€ dispatch.py      # CPU/GPU operation routing
â””â”€â”€ __init__.py      # Package entrypoint
```

---

### ğŸ§  **Why NovaX?**

Traditional Python math libraries (like NumPy) are CPU-bound by default.
NovaX uses GPU memory and fused CUDA kernels to drastically accelerate elementwise operations â€” while keeping the API as simple as possible.

---

### ğŸ§° **Roadmap**

* [ ] Advanced ops (matmul, exp, log, pow)
* [ ] Fused kernels and graph optimization
* [ ] Automatic differentiation
* [ ] Multi-GPU support
* [ ] Integration with PyTorch tensors

---

### ğŸ“¦ **Build & Test**

```bash
# Build wheel
python -m build

# Run tests
pytest -q
```

---

### ğŸ§‘â€ğŸ’» **Contributing**

Contributions welcome!

* Open issues or feature requests on [GitHub Issues](https://github.com/SS-012/novax/issues)
* Fork, create a feature branch (`feature/your-feature`), and submit a PR.

---

### ğŸ“„ **License**

MIT License Â© 2025 [Shohaib Shah](https://github.com/SS-012)
Youâ€™re free to use, modify, and distribute NovaX under the terms of the MIT License.

---

### ğŸŒŸ **Acknowledgments**

* [PyCUDA](https://documen.tician.de/pycuda/) for low-level GPU bindings
* [NumPy](https://numpy.org/) for array semantics inspiration
* [CUDA Python](https://developer.nvidia.com/cuda-python) for kernel execution
